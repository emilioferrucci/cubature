{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "# to use cpu uncomment the following:\n",
    "#import os\n",
    "#os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import roughpy as rp\n",
    "import math\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from diffrax import *\n",
    "import time\n",
    "\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the linear controlled differential equation (CDE)\n",
    "\n",
    "$$ \\mathrm{d}Y = AY \\mathrm{d}X, \\quad Y_0 = y_0, \\qquad \\text{with} \\quad A \\in \\mathcal{L}(\\mathbb R^e \\otimes \\mathbb R^d, \\mathbb R^e), \\quad X \\in C^\\infty([0,1], \\mathbb R^d).$$\n",
    "\n",
    "The solution is given explicitly by \n",
    "\n",
    "$$ Y_1 = \\sum_{n = 0}^\\infty A_{k_n \\gamma_n} A_{k_{n-1} \\gamma_{n-1}}^{k_n} \\cdots A_{k_1 \\gamma_1}^{k_2} y_0^{k_1} S(X)^{\\gamma_1 \\ldots \\gamma_n}_{0,1}. $$\n",
    "\n",
    "with an implicit sum over the $k_i$'s, the indices that run over $1,\\ldots,e$. We want to approximate $Y_1$ by computing the partial sum above up to some $n$, i.e. the one-step level-$n$ Euler approximation.\n",
    "\n",
    "The following example code will do this for a specific example of a $2$-dimensional circular path ($2$ is arbitrary and the rest of the code accommodates general $d$). This won't be important for cubature: the signatures will be swapped out for the exponential of the cubature formula. What matters is that the functions are vmappable over initial conditions, which means the one-step Euler approximations can be concatenated over several intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code obtains the signature of a 2-dimensional circlular path, as a list of jnp arrays.\n",
    "# It can be easily modified to obtain the signature of any d-dimensional path.\n",
    "\n",
    "def circle(t, a, b, c):\n",
    "    return a * np.exp(2 * b * np.pi * 1j * (t + c))\n",
    "\n",
    "def _make_path(x):\n",
    "    def lie_path(t, ctx):\n",
    "        return rp.Lie([x(t).real, x(t).imag], ctx=ctx)\n",
    "    return lie_path\n",
    "\n",
    "def make_signature(x, d, n, res, s, t):\n",
    "    context = rp.get_context(width = d, depth = n, coeffs=rp.DPReal)\n",
    "    function_stream = rp.FunctionStream.from_function(_make_path(x), ctx = context, resolution = res)\n",
    "    return function_stream.signature(rp.RealInterval(s,t))\n",
    "\n",
    "def _sig_degrees(sig, d, n):\n",
    "    expected_length = d ** (n + 1) - 1\n",
    "    assert len(sig) == expected_length, f\"Array length must be {expected_length}, but got {len(sig)}\"\n",
    "    result = []\n",
    "    start = 0\n",
    "    for i in range(n + 1):\n",
    "        length = d ** i\n",
    "        subarray = sig[start:start + length]\n",
    "        result.append(subarray)\n",
    "        start += length\n",
    "    return result\n",
    "\n",
    "def _reshape_level(arr, d, n):\n",
    "    expected_length = d ** n\n",
    "    assert len(arr) == expected_length, f\"Array length must be {expected_length}, but got {len(arr)}\"\n",
    "    \n",
    "    new_shape = (d,) * n\n",
    "    reshaped_array = arr.reshape(new_shape)\n",
    "    return reshaped_array\n",
    "\n",
    "def reshape_signature(sig, d, n): \n",
    "    npsig = np.array(sig)\n",
    "    result = []\n",
    "    k = 0\n",
    "    for arr in _sig_degrees(npsig, d, n):\n",
    "        result.append(jnp.array(_reshape_level(arr, d, k)))\n",
    "        k += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the powers of the tensor A up to order n and stores them in a list of jnp arrays.\n",
    "\n",
    "def powers_up_to(A, n):\n",
    "    matrix = A\n",
    "    result = [matrix]\n",
    "    for i in range(1, n):\n",
    "        subscripts = 'ab' + ''.join(chr(100 + k) for k in range(i)) + ',bc' + chr(100 + i) + '->ac' + ''.join(chr(100 + k) for k in range(i + 1))\n",
    "        matrix = jnp.einsum(subscripts, matrix, A)\n",
    "        result.append(matrix)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the one-step Euler approximation of the linear CDE with given signature.\n",
    "\n",
    "def _make_indices_j(n):\n",
    "    indices_A = 'ab' + ''.join(chr(99 + i) for i in range(n-1, -1, -1))\n",
    "    indices_S = ''.join(chr(99 + i) for i in range(n))\n",
    "    output_indices = 'ab'\n",
    "    return indices_A, indices_S, output_indices\n",
    "\n",
    "def _single_sum_euler(n, y0, An, Sn, indices_list):\n",
    "    R = jnp.einsum(f'{indices_list[0]},{indices_list[1]}->{indices_list[2]}', An, Sn)\n",
    "    return jnp.dot(R, y0)\n",
    "\n",
    "def one_step_euler(n, y0, powers, S, indices_list):\n",
    "    return y0 + sum(_single_sum_euler(k, y0, powers[k], S[k+1], indices_list[k]) for k in range(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is not fully parallelised. Unfortunately, JAX does not support vectorising the call\n",
    "# to _single_sum_euler, as it involves arrays of different shapes. Let's try to use parallelisation\n",
    "# in concurrent.futures instead.\n",
    "\n",
    "import concurrent.futures\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def one_step_euler_cf(n, y0, powers, S, indices_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor: # ProcessPoolExecutor never works\n",
    "        futures = [\n",
    "            executor.submit(_single_sum_euler, k, y0, powers[k], S[k+1], indices_list[k])\n",
    "            for k in range(n-1)\n",
    "        ]\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    return y0 + sum(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 01:15:04.607376: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "# Make the signature (all that matters here is the output).\n",
    "k = 5\n",
    "a = 1/k\n",
    "b = k ** 2\n",
    "c = 0\n",
    "\n",
    "length = b * 2 * np.pi * a\n",
    "area = b * np.pi * (a ** 2)\n",
    "\n",
    "d = 2\n",
    "n = 6\n",
    "s, t = 0, 1\n",
    "\n",
    "sig = make_signature(lambda t: circle(t,a,b,c), d = d, n = n, res = 15, s = s, t = t)\n",
    "\n",
    "rs = reshape_signature(sig, d, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the differential equation. A is drawn from a uniform distribution.\n",
    "\n",
    "e = 4\n",
    "r = 1\n",
    "\n",
    "\n",
    "key0 = jax.random.PRNGKey(0)\n",
    "y0 = jax.random.uniform(key0, (e,))\n",
    "\n",
    "key1 = jax.random.PRNGKey(1)\n",
    "A = jax.random.uniform(key1, (e, e, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004661083221435547\n",
      "0.009574174880981445\n"
     ]
    }
   ],
   "source": [
    "ind_list = [_make_indices_j(k) for k in range(1, n+1)] #make the indices for the einsums\n",
    "pow = powers_up_to(A, n) #compute and store the powers of A\n",
    "\n",
    "# comparison of one_step_euler vs one_step_euler_cf:\n",
    "\n",
    "start = time.time()\n",
    "one_step_euler(n, y0, pow, rs, ind_list)\n",
    "print(time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "one_step_euler_cf(n, y0, pow, rs, ind_list)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential evaluation time:  22.72610902786255\n",
      "vmap evaluation time:  2.423283576965332\n",
      "vmap + concurrent futures evaluation time:  1.7909224033355713\n"
     ]
    }
   ],
   "source": [
    "# Now let's test how much time vmap is saving us. We compare the sequential evaluation of the above\n",
    "# function over many y0's, with the evaluation of the same function using vmap.\n",
    "\n",
    "num_y0s = 10000\n",
    "keys = jax.random.split(key1, num_y0s)\n",
    "random_arrays = [jax.random.uniform(k, (e,)) for k in keys]\n",
    "\n",
    "start = time.time()\n",
    "for y in random_arrays:\n",
    "    one_step_euler(n, y, pow, rs, ind_list)\n",
    "print(\"Sequential evaluation time: \", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "jax.vmap(lambda y: one_step_euler(n, y, pow, rs, ind_list))(jnp.array(random_arrays))\n",
    "print(\"vmap evaluation time: \", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "jax.vmap(lambda y: one_step_euler_cf(n, y, pow, rs, ind_list))(jnp.array(random_arrays))\n",
    "print(\"vmap + concurrent futures evaluation time: \", time.time() - start)\n",
    "\n",
    "# About a 10-fold speedup on Havok, 20-fold on Sauron of using vmap over sequential evaluation.\n",
    "# Lots of issues and few benefits from using one_step_euler_cf. It only seems to work on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmap evaluation time:  1.89339280128479\n",
      "vmap + concurrent futures evaluation time:  1.8314363956451416\n"
     ]
    }
   ],
   "source": [
    "# the first time vmap is run it is slower becuase of compilation, subsequent runs are faster:\n",
    "\n",
    "start = time.time()\n",
    "jax.vmap(lambda y: one_step_euler(n, y, pow, rs, ind_list))(jnp.array(random_arrays))\n",
    "print(\"vmap evaluation time: \", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "jax.vmap(lambda y: one_step_euler_cf(n, y, pow, rs, ind_list))(jnp.array(random_arrays))\n",
    "print(\"vmap + concurrent futures evaluation time: \", time.time() - start)\n",
    "\n",
    "# in fact, after compilation the benefit of using concurrent futures is almost non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very possible the code above isn't fully optimised. One obstacle to removing some of the lists and for loops is that the arrays for the signatures of various levels are of different sizes, and therefore not stackables. This makes it impossible to vectorise operations over them, even though these operations can in principle be done in parallel.\n",
    "\n",
    "The instance of this that I have in mind are the calls to ```_single_sum_euler``` in ```one_step_euler```. I tried to parallelise these calls using ```concurrent.futures```, but this turns out to have negligible benefits and to give lots of errors. It makes sense that classical parallelisation wouldn't work well in JAX, especially when used at the very bottom of a call stack which involves vectorisation (a much more basic form of parallelisation). Going forward it makes sense to use ```one_step_euler```, not ```one_step_euler_cf```.\n",
    "\n",
    "A possible last resort would be to pad the arrays with 0s and to use vmap, which would require some careful rewriting of the code. Note that unless JAX is able to detect sparse arrays it will be doing lots of useless 0 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TracerIntegerConversionError",
     "evalue": "The __index__() method was called on traced array with shape int64[]\nThis BatchTracer with object id 140637968653488 was created on line:\n  /tmp/ipykernel_3822391/2737179216.py:4 (<module>)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerIntegerConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerIntegerConversionError\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Here's the main instance of this limitation. I would like to parallelise the call to _single_sum_euler\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# in the function one_step_euler. However, JAX seems unable to handle this.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m_single_sum_euler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pmap doesn't work either\u001b[39;00m\n\u001b[1;32m      7\u001b[0m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m k:_single_sum_euler(k, y0, \u001b[38;5;28mpow\u001b[39m[k], rs[k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], ind_list[k]))(jnp\u001b[38;5;241m.\u001b[39marange(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Here's the main instance of this limitation. I would like to parallelise the call to _single_sum_euler\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# in the function one_step_euler. However, JAX seems unable to handle this.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m k:_single_sum_euler(k, y0, \u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m, rs[k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], ind_list[k]))(jnp\u001b[38;5;241m.\u001b[39marange(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pmap doesn't work either\u001b[39;00m\n\u001b[1;32m      7\u001b[0m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m k:_single_sum_euler(k, y0, \u001b[38;5;28mpow\u001b[39m[k], rs[k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], ind_list[k]))(jnp\u001b[38;5;241m.\u001b[39marange(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/cubature/.venv/lib/python3.10/site-packages/jax/_src/core.py:1531\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m-> 1531\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerIntegerConversionError(arg)\n",
      "\u001b[0;31mTracerIntegerConversionError\u001b[0m: The __index__() method was called on traced array with shape int64[]\nThis BatchTracer with object id 140637968653488 was created on line:\n  /tmp/ipykernel_3822391/2737179216.py:4 (<module>)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerIntegerConversionError"
     ]
    }
   ],
   "source": [
    "# Here's what goes wrong. I would like to parallelise the call to _single_sum_euler\n",
    "# in the function one_step_euler. However, JAX is unable to handle this.\n",
    "\n",
    "jax.vmap(lambda k:_single_sum_euler(k, y0, pow[k], rs[k+1], ind_list[k]))(jnp.arange(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All input arrays must have the same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This won't work because the arrays are not all of the same shape.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/cubature/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3450\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[1;32m   3448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   3449\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m-> 3450\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3451\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3452\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/cubature/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3081\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[1;32m   3080\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape(a) \u001b[38;5;241m!=\u001b[39m shape0:\n\u001b[0;32m-> 3081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll input arrays must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3082\u001b[0m   new_arrays\u001b[38;5;241m.\u001b[39mappend(expand_dims(a, axis))\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(new_arrays, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: All input arrays must have the same shape."
     ]
    }
   ],
   "source": [
    "# Making an array from the list won't work because the arrays are not all of the same shape.\n",
    "p = jnp.array(pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TracerIntegerConversionError",
     "evalue": "The __index__() method was called on traced array with shape int64[]\nThe error occurred while tracing the function <lambda> at /tmp/ipykernel_3822391/1602965186.py:2 for pmap. This concrete value was not available in Python because it depends on the value of the argument k.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerIntegerConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerIntegerConversionError\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pmap doesn't work either\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m_single_sum_euler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pmap doesn't work either\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m jax\u001b[38;5;241m.\u001b[39mpmap(\u001b[38;5;28;01mlambda\u001b[39;00m k:_single_sum_euler(k, y0, \u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m, rs[k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], ind_list[k]))(jnp\u001b[38;5;241m.\u001b[39marange(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/cubature/.venv/lib/python3.10/site-packages/jax/_src/core.py:1531\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m-> 1531\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerIntegerConversionError(arg)\n",
      "\u001b[0;31mTracerIntegerConversionError\u001b[0m: The __index__() method was called on traced array with shape int64[]\nThe error occurred while tracing the function <lambda> at /tmp/ipykernel_3822391/1602965186.py:2 for pmap. This concrete value was not available in Python because it depends on the value of the argument k.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerIntegerConversionError"
     ]
    }
   ],
   "source": [
    "# pmap doesn't work either\n",
    "jax.pmap(lambda k:_single_sum_euler(k, y0, pow[k], rs[k+1], ind_list[k]))(jnp.arange(n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_y0s = 100000\n",
    "keys = jax.random.split(key1, num_y0s)\n",
    "random_arrays = jnp.array([jax.random.uniform(k, (e,)) for k in keys]) # vectorise this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmap evaluation time:  0.004851341247558594\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "jax.vmap(lambda y: _single_sum_euler(n, y, pow[5], rs[6], ind_list[5]))(random_arrays)\n",
    "print(\"vmap evaluation time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential evaluation time:  36.801605224609375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for y in random_arrays:\n",
    "    _single_sum_euler(n, y, pow[5], rs[6], ind_list[5])\n",
    "print(\"Sequential evaluation time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok I know what to do! Vectorise each level separately, and then if necessary parallelise (outside of JAX) across levels. This is going to be super fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
